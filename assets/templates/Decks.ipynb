{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yugiquery import *\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "header(\"My Decks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "=================\n",
    "\n",
    "*   [1  Data loading](#Data-loading)\n",
    "    *   [1.1  Read collection](#Read-collection)\n",
    "*   [2  Check changes](#Check-changes)\n",
    "    *   [2.1  Load previous data](#Load-previous-data)\n",
    "    *   [2.2  Generate changelogs](#Generate-changelogs)\n",
    "    *   [2.3  Save data](#Save-data)\n",
    "*   [3  Data visualization](#Data-visualization)\n",
    "    *   [3.1  Full data](#Full-data)\n",
    "    *   [3.2  Card types](#Card-types)\n",
    "    *   [3.3  Monsters](#Monsters)\n",
    "        *   [3.3.1  Attributes](#Attributes)\n",
    "        *   [3.3.2  Primary types](#Primary-types)\n",
    "            *   [3.3.2.1  Has effect discrimination](#Has-effect-discrimination)\n",
    "            *   [3.3.2.2  Is pendulum discrimination](#Is-pendulum-discrimination)\n",
    "            *   [3.3.2.3  By attribute](#By-attribute)\n",
    "        *   [3.3.3  Secondary types](#Secondary-types)\n",
    "            *   [3.3.3.1  By attribute](#By-attribute)\n",
    "            *   [3.3.3.2  By secondary type](#By-secondary-type)\n",
    "        *   [3.3.4  Monster types](#Monster-types)\n",
    "            *   [3.3.4.1  By Attribute](#By-Attribute)\n",
    "            *   [3.3.4.2  By primary type](#By-primary-type)\n",
    "            *   [3.3.4.3  By secondary type](#By-secondary-type)\n",
    "        *   [3.3.5  ATK](#ATK)\n",
    "        *   [3.3.6  DEF](#DEF)\n",
    "        *   [3.3.7  Level/Rank](#Level/Rank)\n",
    "            *   [3.3.7.1  ATK statistics](#ATK-statistics)\n",
    "            *   [3.3.7.2  DEF statistics](#DEF-statistics)\n",
    "        *   [3.3.8  Pendulum scale](#Pendulum-scale)\n",
    "            *   [3.3.8.1  ATK statistics](#ATK-statistics)\n",
    "            *   [3.3.8.2  DEF statistics](#DEF-statistics)\n",
    "            *   [3.3.8.3  Level/Rank statistics](#Level/Rank-statistics)\n",
    "        *   [3.3.9  Link](#Link)\n",
    "            *   [3.3.9.1  ATK statistics](#ATK-statistics)\n",
    "        *   [3.3.10  Link Arrows](#Link-Arrows)\n",
    "            *   [3.3.10.1  By combination](#By-combination)\n",
    "            *   [3.3.10.2  By unique](#By-unique)\n",
    "            *   [3.3.10.3  By link](#By-link)\n",
    "    *   [3.4  Spell & Trap](#Spell-&-Trap)\n",
    "        *   [3.4.1  Properties](#Properties)\n",
    "    *   [3.5  Effect type](#Effect-type)\n",
    "        *   [3.5.1  Card type discrimination](#Card-type-discrimination)\n",
    "    *   [3.6  Archseries](#Archseries)\n",
    "        *   [3.6.1  By card type](#By-card-type)\n",
    "        *   [3.6.2  By primary type](#By-primary-type)\n",
    "        *   [3.6.3  By secondary type](#By-secondary-type)\n",
    "        *   [3.6.4  By monster type](#By-monster-type)\n",
    "        *   [3.6.5  By property](#By-property)\n",
    "    *   [3.7  Artworks](#Artworks)\n",
    "        *   [3.7.1  By card type](#By-card-type)\n",
    "        *   [3.7.2  By primary type](#By-primary-type)\n",
    "    *   [3.8  Errata](#Errata)\n",
    "        *   [3.8.1  By card type](#By-card-type)\n",
    "        *   [3.8.2  By primary type](#By-primary-type)\n",
    "        *   [3.8.3  By artwork](#By-artwork)\n",
    "    *   [3.9  TCG & OCG status](#TCG-&-OCG-status)\n",
    "        *   [3.9.1  TGC status](#TGC-status)\n",
    "            *   [3.9.1.1  By card type](#By-card-type)\n",
    "            *   [3.9.1.2  By monster type](#By-monster-type)\n",
    "            *   [3.9.1.3  By archseries](#By-archseries)\n",
    "        *   [3.9.2  OCG status](#OCG-status)\n",
    "            *   [3.9.2.1  By card type](#By-card-type)\n",
    "            *   [3.9.2.2  By monster type](#By-monster-type)\n",
    "            *   [3.9.2.3  By archseries](#By-archseries)\n",
    "        *   [3.9.3  TCG vs. OCG status](#TCG-vs.-OCG-status)\n",
    "*   [4  Epilogue](#Epilogue)\n",
    "    *   [4.1  HTML export](#HTML-export)\n",
    "<!-- *   [4.2  Git](#Git) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = git.ensure_repo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp\n",
    "timestamp = arrow.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load decks from YDK and decklist files\n",
    "deck_df = pd.concat([get_ydk(), get_decklists()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cards(collections: List[pd.DataFrame] | pd.DataFrame, merge_data=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process a DataFrame with card names, numbers and/or passwords and return a DataFrame with the card names, quantities and, optionally, additional card data merged from database.\n",
    "\n",
    "    Args:\n",
    "        collections (List[pd.DataFrame] | pd.DataFrame): DataFrame or list of DataFrames with card names, numbers and/or passwords.\n",
    "\n",
    "    Returns:\n",
    "        ((List[pd.DataFrame] | pd.DataFrame): DataFrame or list of DataFrames with card names, quantities and, optionally, additional card data merged from database.\n",
    "    \"\"\"\n",
    "    if not isinstance(collections, list):\n",
    "        collections = [collections]\n",
    "\n",
    "    card_df, _ = load_latest_data(name_pattern=\"cards\")\n",
    "    if any(\n",
    "        [\n",
    "            \"Card number\" in collection_df and not collection_df[collection_df[\"Name\"].isna()][\"Card number\"].empty\n",
    "            for collection_df in collections\n",
    "        ]\n",
    "    ):\n",
    "        set_lists_df, _ = load_latest_data(name_pattern=\"sets\")\n",
    "\n",
    "    for i, collection_df in enumerate(collections):\n",
    "        collection_df = collection_df.dropna(how=\"all\", axis=1).dropna(how=\"all\", axis=0)\n",
    "        collection_df = collection_df.assign(match=np.nan).astype(object)\n",
    "\n",
    "        if \"Card number\" in collection_df and not collection_df[\"Card number\"].dropna().empty:\n",
    "            number_keys = collection_df[\"Card number\"].dropna().str.upper().str.strip()\n",
    "\n",
    "            list_keys = set_lists_df[\"Card number\"].dropna().str.upper().str.strip()\n",
    "            list_values = set_lists_df.loc[list_keys.index][\"Name\"]\n",
    "            key_name_dict = dict(zip(list_keys, list_values))\n",
    "\n",
    "            missing = number_keys[~number_keys.isin(list_keys)]\n",
    "            if missing.count() > 0:\n",
    "                print(\n",
    "                    \"\\nUnable to find the following card(s) by number:\\n ⏺\",\n",
    "                    \"\\n ⏺ \".join(missing.sort_values().unique()),\n",
    "                )\n",
    "\n",
    "            matches = number_keys.map(lambda x: key_name_dict.get(x, x))\n",
    "            collection_df.loc[matches.index, \"match\"] = matches\n",
    "            collection_df.drop(\"Card number\", axis=1, inplace=True)\n",
    "\n",
    "        if \"Password\" in collection_df and not collection_df[collection_df[\"match\"].isna()][\"Password\"].empty:\n",
    "            password_keys = collection_df[collection_df[\"match\"].isna()][\"Password\"].dropna().astype(int)\n",
    "            list_keys = card_df[\"Password\"].dropna().astype(int)\n",
    "            list_values = card_df.loc[list_keys.index][\"Name\"]\n",
    "            key_name_dict = dict(zip(list_keys, list_values))\n",
    "\n",
    "            missing = password_keys[~password_keys.isin(list_keys)]\n",
    "            if missing.count() > 0:\n",
    "                print(\n",
    "                    \"\\nUnable to find the following card(s) by password:\\n ⏺\",\n",
    "                    \"\\n ⏺ \".join(missing.sort_values().unique().astype(str)),\n",
    "                )\n",
    "\n",
    "            matches = password_keys.map(lambda x: key_name_dict.get(x, x))\n",
    "            collection_df.loc[matches.index, \"match\"] = matches\n",
    "            collection_df.drop(\"Password\", axis=1, inplace=True)\n",
    "\n",
    "        if \"Name\" in collection_df and not collection_df[collection_df[\"match\"].isna()][\"Name\"].empty:\n",
    "            name_keys = collection_df[\"Name\"].dropna().str.lower().str.strip()\n",
    "            list_keys = card_df[\"Name\"].str.lower().str.strip()\n",
    "            key_name_dict = dict(zip(list_keys, card_df[\"Name\"]))\n",
    "\n",
    "            missing = collection_df[\"Name\"].dropna()[~name_keys.isin(list_keys)]\n",
    "            if missing.count() > 0:\n",
    "                print(\"\\nUnable to find the following card(s) by name:\\n ⏺\", \"\\n ⏺ \".join(missing.sort_values().unique()))\n",
    "\n",
    "            # Map the \"Name\" column from list_df to collection_df based on the keys\n",
    "            matches = name_keys.map(lambda x: key_name_dict.get(x, x))\n",
    "            collection_df.loc[matches.index, \"match\"] = matches\n",
    "            collection_df.drop(\"Name\", axis=1, inplace=True)\n",
    "\n",
    "        collection_df = collection_df.rename(columns={\"match\": \"Name\"})\n",
    "        columns = list(collection_df.columns.difference([\"Count\"]))\n",
    "        collection_df = collection_df.dropna(how=\"all\", axis=1).dropna(how=\"all\", axis=0)\n",
    "        collection_df = collection_df.groupby(columns, dropna=False).sum().reset_index()\n",
    "        if merge_data:\n",
    "            collection_df = collection_df.merge(card_df.drop_duplicates(subset=\"Name\"), on=\"Name\", how=\"left\")\n",
    "        collections[i] = collection_df\n",
    "\n",
    "    print(\"\\nCollection data processed.\")\n",
    "    if len(collections) == 1:\n",
    "        return collections[0]\n",
    "    else:\n",
    "        return collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the deck data frame\n",
    "deck_df = find_cards(deck_df, merge_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest file if exist\n",
    "previous_deck_df, previousdeck_ts = load_latest_data(\"deck\")\n",
    "\n",
    "if previous_deck_df is not None:\n",
    "    previous_deck_df = previous_deck_df.astype(\n",
    "        deck_df[previous_deck_df.columns.intersection(deck_df.columns)].dtypes.to_dict()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if previous_deck_df is None:\n",
    "    deck_changelog = None\n",
    "    print(\"Skipped\")\n",
    "else:\n",
    "    deck_changelog = generate_changelog(previous_deck_df, deck_df, col=\"Name\")\n",
    "    if not deck_changelog.empty:\n",
    "        display(deck_changelog)\n",
    "        deck_changelog.to_csv(\n",
    "            dirs.DATA\n",
    "            / make_filename(\n",
    "                report=\"deck\",\n",
    "                timestamp=timestamp,\n",
    "                previous_timestamp=previous_deck_df,\n",
    "            ),\n",
    "            index=True,\n",
    "        )\n",
    "        print(\"Changelog saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if deck_changelog is not None and deck_changelog.empty:\n",
    "    print(\"No changes. New data not saved\")\n",
    "else:\n",
    "    deck_df.to_csv(\n",
    "        dirs.DATA / make_filename(report=\"deck\", timestamp=timestamp),\n",
    "        index=False,\n",
    "    )\n",
    "    print(\"Data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other\n",
    "\n",
    "# Merge the collection and deck data frames\n",
    "collection_df = get_collection()\n",
    "if collection_df is not None:\n",
    "    collection_df = assign_deck(collection_df, deck_df=deck_df, return_collection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
